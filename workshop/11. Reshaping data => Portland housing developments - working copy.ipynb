{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping data: Portland housing developments\n",
    "\n",
    "In this notebook, we're going to work with some data on Portland (Oregon) housing developments since 2014. Right now, the data are scattered across a jillion spreadsheets. Our goal is to parse them all into one clean CSV. (Thanks to [Kelly Kenoyer of the Portland Mercury](https://twitter.com/Kelly_Kenoyer) for donating this data.)\n",
    "\n",
    "The spreadsheets, a mixture of `xls` and `xlsx` files, live in `../data/portland/`. A few things to note:\n",
    "- Some of the spreadsheets have extra columns\n",
    "- Some of the spreadsheets have other worksheets in addition to the data worksheet (pivot tables, mostly) -- but these are not always in the same position\n",
    "- Some of the spreadsheets have columns of mostly blank data that the city once used to manually aggregate data by category -- we don't want these columns\n",
    "- Some of the spreadsheets have blank rows\n",
    "\n",
    "Our strategy:\n",
    "- Get a list of Excel files in that directory using the [`glob`](https://docs.python.org/3/library/glob.html) module\n",
    "- Create an empty pandas data frame\n",
    "- Loop over the list of spreadsheet files and ...\n",
    "    - Read in the file to a data frame\n",
    "    - Find the correct worksheet\n",
    "    - Drop empty columns and rows\n",
    "    - Append to the main data frame\n",
    "    \n",
    "First, we'll import `glob` and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob and pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use `glob` to get a list of the files we're going to loop over. We'll use the asterisk `*`, which means \"match everything.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glob to find everything in the `../data/portland/` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print that list to make sure we have what we think we have\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create an empty data frame. This will be the container we stuff the data into as we loop over the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we're dealing with. We're going to loop over the spreadsheet, and for each one, we're going to look at:\n",
    "- The names of the worksheets in that spreadsheet\n",
    "- The columns in each worksheet\n",
    "\n",
    "This will help us decide, later, which worksheets we need to target.\n",
    "\n",
    "We're going to take advantage of the fact, [according to the `read_excel()` documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html), that you can pass `None` as the `sheet_names` argument and pandas will read in _all_ of the sheets as a big dictionary -- the keys are the names of the worksheets, the values are the associated data frames.\n",
    "\n",
    "Later, our logic will go like this:\n",
    "- Read in every worksheet as a data frame\n",
    "- Target the worksheet whose name matches the pattern for the data we need\n",
    "\n",
    "ðŸ‘‰ For a refresher on _for loops_ and dictionaries, [check out this notebook](../reference/Python%20data%20types%20and%20basic%20syntax.ipynb#for-loops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the excel file paths\n",
    "\n",
    "    \n",
    "    # load the file into a data frame\n",
    "    # specifying `None` as the sheet name\n",
    "\n",
    "    \n",
    "    # print the name of the file\n",
    "\n",
    "    \n",
    "    # print the worksheet names\n",
    "    # -- the .keys() in the dictionary\n",
    "\n",
    "    \n",
    "    # print a divider to make scanning easier\n",
    "\n",
    "    \n",
    "    # and an empty line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. So it looks like our target sheets are called a few different things: `nrs`, `04_2016 New Res Units'`, `'2018 04 New Residential Units'`, etc.\n",
    "\n",
    "Can we come up with a list of patterns to match all of them? I think we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the items in this list are lowercased,\n",
    "# because we're gonna match on .lower()'d versions of the sheet names\n",
    "target_sheet_name_fragments = ['new res', 'nrs', 'lus stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we need to write some logic that says: Pick the worksheet that has one of our `target_sheet_name_fragments` in the name. A nested pair of _for loops_ will do the trick for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the excel file paths\n",
    "\n",
    "    \n",
    "    # load the file into a data frame\n",
    "    # specifying `None` as the sheet name\n",
    "\n",
    "        \n",
    "    # start off with no match -- None\n",
    "\n",
    "    \n",
    "    # loop over the worksheet names\n",
    "\n",
    "        \n",
    "        # loop over the word fragments\n",
    "\n",
    "            \n",
    "            # if this fragment exists in the lowercased worksheet name\n",
    "\n",
    "                \n",
    "                # we've got a winner\n",
    "\n",
    "    # if, when we get to the end of this, `match` is still None\n",
    "\n",
    "        # print something to let us know about it\n",
    "\n",
    "        \n",
    "        # and the names of the sheets\n",
    "\n",
    "        \n",
    "        # and break out of the loop\n",
    "\n",
    "    \n",
    "    # otherwise, grab a handle to the worksheet we want\n",
    "\n",
    "    \n",
    "    # print a status message to let us know what's up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning through that list, I feel comfortable that we're grabbing the correct data. Let's take a look at the columns in each worksheet we'll be parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the excel file paths\n",
    "\n",
    "    \n",
    "    # load the file into a data frame\n",
    "    # specifying `None` as the sheet name\n",
    "\n",
    "        \n",
    "    # start off with no match - None\n",
    "\n",
    "    \n",
    "    # loop over the worksheet names\n",
    "\n",
    "        \n",
    "        # loop over the word fragments\n",
    "\n",
    "            \n",
    "            # if this fragment exists in the lowercased worksheet name\n",
    "\n",
    "                \n",
    "                # we've got a winner\n",
    "\n",
    "    # if, when we get to the end of this, `match` is still None\n",
    "\n",
    "        # print something to let us know about it\n",
    "\n",
    "        \n",
    "        # and the names of the sheets\n",
    "\n",
    "        \n",
    "        # and break out of the loop\n",
    "\n",
    "\n",
    "    # otherwise, grab a handle to the worksheet we want\n",
    "\n",
    "    \n",
    "    # print a status message to let us know what's up\n",
    "\n",
    "    \n",
    "    # print a sorted list of column names\n",
    "\n",
    "    \n",
    "    # print a divider to make scanning our results easier\n",
    "\n",
    "    \n",
    "    # print an empty line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that some columns are, e.g. `Unnamed: 4`. That means there's no column header. Let's take a look at one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('../data/portland/08_2014 New Res Units.xls', sheet_name='08_2014 New Res Units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they're using those columns to total up the valuations for groups of housing types. I'm noticing, too, that there are some blank rows -- probably used as dividers between groups -- so we'll want to drop those as well.\n",
    "\n",
    "We'll keep that in mind as we roll through these sheets.\n",
    "\n",
    "Here's the pandas documentation on the methods we'll be using here:\n",
    "- [`append()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.append.html)\n",
    "- [`drop()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)\n",
    "- [`dropna()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the excel file paths\n",
    "\n",
    "    \n",
    "    # load the file into a data frame\n",
    "    # specifying `None` as the sheet name\n",
    "\n",
    "\n",
    "    # start off with no match\n",
    "\n",
    "    \n",
    "    # loop over the worksheet names\n",
    "\n",
    "        \n",
    "        # loop over the word fragments\n",
    "\n",
    "            \n",
    "            # if this fragment exists in the lowercased worksheet name\n",
    "\n",
    "                \n",
    "                # we've got a winner\n",
    "\n",
    "\n",
    "    # if, when we get to the end of this, `match` is still None\n",
    "\n",
    "        # print something to let us know about it\n",
    "\n",
    "        \n",
    "        # and the names of the sheets\n",
    "\n",
    "        \n",
    "        # and break out of the loop\n",
    "\n",
    "                \n",
    "    # otherwise, grab a handle to the worksheet we want\n",
    "\n",
    "    \n",
    "    # print a status message to let us know what's up\n",
    "\n",
    "    \n",
    "    # get a list of columns we want to drop\n",
    "\n",
    "    \n",
    "    # drop those bad boys\n",
    "\n",
    "\n",
    "    # drop empty rows in place, but only if _all_ of the values are nulls\n",
    "\n",
    "    \n",
    "    # append to our `housing` data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out with head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing I'd do, before writing out to file, is parse the date columns as dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"indate\" column to datetime\n",
    "\n",
    "\n",
    "# convert \"indate\" column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it out with head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `to_csv()` method to write out to a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to 'portland-developments.csv'\n",
    "# specify no index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
